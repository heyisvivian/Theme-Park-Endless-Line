{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e4a58c3-b759-4001-b0dd-ea14292d6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17347b8c-035d-4b5c-9e44-ae7ed6c1db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_generate_data = False\n",
    "to_train = True\n",
    "to_test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be07084-64fd-4984-9e3c-e8d69053089b",
   "metadata": {},
   "source": [
    "*Data Preparation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd974912-f5bd-4e8e-bfd4-72e4fe66a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_generate_data:\n",
    "    df = pd.read_parquet('autodl-tmp/mins_data.parquet')\n",
    "    df.sort_values(by=['START_TIME', 'Attraction'], inplace=True)\n",
    "    df['lag1'] = df.groupby('Attraction')['WAIT_TIME_MAX'].shift(1).fillna(0)\n",
    "    df['lag2'] = df.groupby('Attraction')['WAIT_TIME_MAX'].shift(2).fillna(0)\n",
    "    df.reset_index(inplace = True,drop = True)\n",
    "    one_hot_columns = [col for col in df.columns if \n",
    "                       pd.api.types.is_numeric_dtype(df[col]) and \n",
    "                       sorted(df[col].unique()) == [0, 1]]\n",
    "    non_one_hot_columns = [col for col in df.columns if \n",
    "                           pd.api.types.is_numeric_dtype(df[col]) and \n",
    "                           col not in one_hot_columns and col not in ['lag1','lag2','WAIT_TIME_MAX']]\n",
    "    scaler = StandardScaler()\n",
    "    df[non_one_hot_columns] = scaler.fit_transform(df[non_one_hot_columns])\n",
    "    \n",
    "    num_attractions = len(df.Attraction.unique())\n",
    "    grouped = df.groupby('START_TIME')\n",
    "    feature_columns = [i for i in list(df) if i not in ['WORK_DATE',\n",
    "     'START_TIME',\n",
    "     'Attraction',\n",
    "     'WAIT_TIME_MAX',\n",
    "     'DEB_TIME',\n",
    "     'FIN_TIME',\n",
    "     'DEB_TIME_x',\n",
    "     'FIN_TIME_x',\n",
    "     'DEB_TIME_y',\n",
    "     'FIN_TIME_y']]\n",
    "    zero_data = np.zeros((1, len(feature_columns)))\n",
    "    zero_df = pd.DataFrame(zero_data, columns=feature_columns)\n",
    "    processed_groups = []\n",
    "    targets = []\n",
    "    all_attractions = sorted(df['Attraction'].unique())\n",
    "    for time_point, group in tqdm(grouped):\n",
    "        processed_group = group.copy()\n",
    "        processed_group = processed_group.drop_duplicates(subset=['Attraction'], keep='first')\n",
    "        present_attractions = group['Attraction'].unique()\n",
    "        missing_attractions = set(all_attractions) - set(present_attractions)\n",
    "        for attraction in missing_attractions:\n",
    "            temp_df = zero_df.copy()\n",
    "            temp_df['Attraction'] = attraction\n",
    "            temp_df['START_TIME'] = time_point\n",
    "            processed_group = pd.concat([processed_group, temp_df], ignore_index=True)\n",
    "        processed_group.sort_values(by=['Attraction'], inplace=True)\n",
    "        t = processed_group.pop('WAIT_TIME_MAX').fillna(0)\n",
    "        data = torch.tensor(processed_group[feature_columns].values, dtype=torch.float)\n",
    "        processed_groups.append(data)\n",
    "        targets.append(t)\n",
    "        if data.shape[0] != 26:\n",
    "            break\n",
    "    features_tensor = torch.stack(processed_groups)\n",
    "    labels_tensor = torch.tensor(np.array(targets))\n",
    "    total_samples = len(features_tensor)\n",
    "    # last 10% for validation\n",
    "    split_idx = int(total_samples * 0.9)\n",
    "    \n",
    "    train_features = features_tensor[:split_idx]\n",
    "    train_labels = labels_tensor[:split_idx]\n",
    "    validation_features = features_tensor[split_idx:]\n",
    "    validation_labels = labels_tensor[split_idx:]\n",
    "    \n",
    "    train_dataset = TensorDataset(train_features, train_labels)\n",
    "    validation_dataset = TensorDataset(validation_features, validation_labels)\n",
    "    torch.save(train_dataset, 'autodl-tmp/train_dataset.pth')\n",
    "    torch.save(validation_dataset, 'autodl-tmp/validation_dataset.pth')\n",
    "else:\n",
    "    df = pd.read_parquet('autodl-tmp/mins_data.parquet')\n",
    "    df.sort_values(by=['START_TIME', 'Attraction'], inplace=True)\n",
    "    df['lag1'] = df.groupby('Attraction')['WAIT_TIME_MAX'].shift(1).fillna(0)\n",
    "    df['lag2'] = df.groupby('Attraction')['WAIT_TIME_MAX'].shift(2).fillna(0)\n",
    "    df.reset_index(inplace = True,drop = True)\n",
    "    one_hot_columns = [col for col in df.columns if \n",
    "                       pd.api.types.is_numeric_dtype(df[col]) and \n",
    "                       sorted(df[col].unique()) == [0, 1]]\n",
    "    non_one_hot_columns = [col for col in df.columns if \n",
    "                           pd.api.types.is_numeric_dtype(df[col]) and \n",
    "                           col not in one_hot_columns and col not in ['lag1','lag2','WAIT_TIME_MAX']]\n",
    "    scaler = StandardScaler()\n",
    "    df[non_one_hot_columns] = scaler.fit_transform(df[non_one_hot_columns])\n",
    "    \n",
    "    num_attractions = len(df.Attraction.unique())\n",
    "    grouped = df.groupby('START_TIME')\n",
    "    feature_columns = [i for i in list(df) if i not in ['WORK_DATE',\n",
    "     'START_TIME',\n",
    "     'Attraction',\n",
    "     'WAIT_TIME_MAX',\n",
    "     'DEB_TIME',\n",
    "     'FIN_TIME',\n",
    "     'DEB_TIME_x',\n",
    "     'FIN_TIME_x',\n",
    "     'DEB_TIME_y',\n",
    "     'FIN_TIME_y']]\n",
    "    train_dataset = torch.load('autodl-tmp/train_dataset.pth')\n",
    "    validation_dataset = torch.load('autodl-tmp/validation_dataset.pth')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fbca7-482e-4e6a-a8b4-513d3562d727",
   "metadata": {},
   "source": [
    "*Network design*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d5d20c-cf1f-4eea-a028-f17d0ffce0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network1(nn.Module):\n",
    "    #version 1: input-1500-1000-output\n",
    "    #version 2: input-1500-1500-1000-output\n",
    "    def __init__(self, input_size, output_size, num_layers=1):\n",
    "        super(Network1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1500)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1500, 1500)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(1500, 1000)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(1000, output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
    "    def forward(self, x, return_intermediate=False):\n",
    "        intermediate_outputs = {}\n",
    "        out = self.relu(self.fc1(x))\n",
    "        intermediate_outputs['fc1'] = out\n",
    "        out = self.dropout1(out)\n",
    "        intermediate_outputs['dropout1'] = out\n",
    "        out = self.relu(self.fc2(out))\n",
    "        intermediate_outputs['fc2'] = out\n",
    "        out = self.dropout2(out)\n",
    "        intermediate_outputs['dropout2'] = out\n",
    "        out = self.relu(self.fc3(out))\n",
    "        intermediate_outputs['fc3'] = out\n",
    "        out = self.dropout3(out)\n",
    "        intermediate_outputs['dropout3'] = out\n",
    "        out = self.fc4(out)\n",
    "        intermediate_outputs['fc4'] = out\n",
    "\n",
    "        if return_intermediate:\n",
    "            return intermediate_outputs\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "class Network2(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(Network2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.fc4 = nn.Linear(128, output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout1(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "network1 = Network1(input_size=num_attractions*len(feature_columns),\n",
    "                    output_size=num_attractions*num_attractions).to(device)\n",
    "network2 = Network2(input_size=num_attractions, output_size=num_attractions).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bbe3d0e-3162-4159-a92f-3d86cf32b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_initial_matrix(out):\n",
    "    matrix = out.view(26, 26)\n",
    "    normalized_matrix = matrix / matrix.sum(dim=1, keepdim=True)\n",
    "    return normalized_matrix\n",
    "def calculate_stationary_matrix(matrix, num_iterations=30, epsilon=1e-6):\n",
    "    v = torch.ones(matrix.size(0), dtype=matrix.dtype, device=matrix.device)\n",
    "    v = v / v.sum()\n",
    "    for _ in range(num_iterations):\n",
    "        v_next = torch.mv(matrix, v)\n",
    "        v_next = v_next / v_next.sum()\n",
    "        if torch.norm(v - v_next) < epsilon:\n",
    "            break\n",
    "        v = v_next\n",
    "    return v\n",
    "\n",
    "def Middle(out):\n",
    "    return calculate_stationary_matrix(build_initial_matrix(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa00a87a-57fc-4faf-b0c1-da546a60c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_train:\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer1 = optim.Adam(network1.parameters(), lr=0.001)\n",
    "    optimizer2 = optim.Adam(network2.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf2dd2-0dd2-4aad-a776-b74b7d976821",
   "metadata": {},
   "source": [
    "*Evaluation Design*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c9ff8ea-c643-4def-b2da-af9b1c6e6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model1, model2, validation_loader, criterion, device):\n",
    "    model1.eval() \n",
    "    model2.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): \n",
    "        for inputs, targets in validation_loader:\n",
    "            inputs = inputs.reshape((1,num_attractions*len(feature_columns))).float()\n",
    "            inputs, targets = inputs.to(device), targets.float().to(device)\n",
    "            out1 = model1(inputs)\n",
    "            intermediate_matrix = build_initial_matrix(out1)\n",
    "            stationary_matrix = calculate_stationary_matrix(intermediate_matrix)\n",
    "            predictions = model2(stationary_matrix)\n",
    "            loss = criterion(predictions, targets)\n",
    "            val_loss += loss.item()\n",
    "    return np.sqrt(val_loss / len(validation_loader))\n",
    "def RMSE_for_Attraction(network1,network2):\n",
    "    attraction = df.Attraction.unique()\n",
    "    attraction.sort()\n",
    "    network1.eval() \n",
    "    network2.eval()\n",
    "    result = pd.DataFrame({'attraction':attraction,'RMSE':[0 for i in attraction]})\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): \n",
    "        for inputs, targets in tqdm(validation_loader):\n",
    "            targets = targets.reshape(26)\n",
    "            inputs = inputs.reshape((1,num_attractions*len(feature_columns))).float()\n",
    "            inputs, targets = inputs.to(device), targets.float().to(device)\n",
    "            out1 = network1(inputs)\n",
    "            intermediate_matrix = build_initial_matrix(out1)\n",
    "            stationary_matrix = calculate_stationary_matrix(intermediate_matrix)\n",
    "            predictions = network2(stationary_matrix)\n",
    "            for i in range(len(predictions)):\n",
    "                index = result['attraction'] == attraction[i]\n",
    "                result.loc[index, 'RMSE'] += float((targets[i] - predictions[i]))**2\n",
    "    result.RMSE = result.RMSE/len(validation_loader)\n",
    "    result.RMSE = result.RMSE.apply(lambda x:np.sqrt(x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63567853-5a18-4a3a-b2f2-acbc86d8100f",
   "metadata": {},
   "source": [
    "*Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f388bf-6e8c-4058-b70b-6fe71e173686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 36540/36540 [05:24<00:00, 112.78it/s, Train Loss=421] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 36540/36540 [06:03<00:00, 100.58it/s, Train Loss=455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.8362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 36540/36540 [05:38<00:00, 107.89it/s, Train Loss=418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 36540/36540 [05:28<00:00, 111.39it/s, Train Loss=395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 36540/36540 [05:32<00:00, 110.01it/s, Train Loss=817]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.7396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 36540/36540 [05:37<00:00, 108.26it/s, Train Loss=1.98e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 36540/36540 [05:48<00:00, 104.91it/s, Train Loss=343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 20.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 36540/36540 [06:58<00:00, 87.36it/s, Train Loss=1.08e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 36540/36540 [07:43<00:00, 78.81it/s, Train Loss=4.5e+6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 26.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 36540/36540 [07:58<00:00, 76.40it/s, Train Loss=4.48e+6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 28.2354\n"
     ]
    }
   ],
   "source": [
    "if to_train:\n",
    "    num_epochs = 10\n",
    "    current_best = 1e10\n",
    "    RMSE_val = []\n",
    "    for epoch in range(num_epochs):\n",
    "        network1.train()\n",
    "        network2.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs = inputs.reshape((1,num_attractions*len(feature_columns))).float()\n",
    "            inputs, targets = inputs.to(device), targets.float().to(device)\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "            out1 = network1(inputs)\n",
    "            stationary_matrix = Middle(out1)\n",
    "            predictions = network2(stationary_matrix).reshape((1,26)).float()\n",
    "            loss = criterion(predictions, targets)\n",
    "            loss.backward()\n",
    "            clip_value = 1 #1-10\n",
    "            nn.utils.clip_grad_norm_(network1.parameters(), clip_value) \n",
    "            nn.utils.clip_grad_norm_(network2.parameters(), clip_value)\n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'Train Loss': train_loss / (batch_idx + 1)})\n",
    "            \n",
    "        val_loss = validate(network1, network2, validation_loader, criterion, device)\n",
    "        RMSE_val.append(val_loss)\n",
    "        if np.sqrt(val_loss) < current_best:\n",
    "            torch.save(network1, 'network1_v2.pth')\n",
    "            torch.save(network2, 'network2_v2.pth')\n",
    "            current_best = val_loss\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd19c76-d229-4603-9144-d55979230d98",
   "metadata": {},
   "source": [
    "*Best Model Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8532592-870f-44d4-b3ab-7f0166b3a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for all Attractions 17.653672616149745\n",
      "          attraction       RMSE\n",
      "0        Bumper Cars   7.623577\n",
      "1        Bungee Jump  20.003759\n",
      "2       Circus Train   3.888419\n",
      "3        Crazy Dance   3.705589\n",
      "4      Dizzy Dropper  10.570900\n",
      "5         Drop Tower  21.876137\n",
      "6     Flying Coaster  14.044068\n",
      "7          Free Fall  44.365342\n",
      "8        Giant Wheel  21.154676\n",
      "9       Giga Coaster   9.930772\n",
      "10          Go-Karts  21.436050\n",
      "11     Haunted House  14.451574\n",
      "12     Himalaya Ride   2.787177\n",
      "13  Inverted Coaster  22.863536\n",
      "14    Kiddie Coaster  11.530456\n",
      "15    Merry Go Round  13.787891\n",
      "16        Oz Theatre   5.651201\n",
      "17       Rapids Ride  17.194991\n",
      "18    Roller Coaster  23.407296\n",
      "19  Spinning Coaster  14.330277\n",
      "20      Spiral Slide  79.192839\n",
      "21     Superman Ride   7.905478\n",
      "22        Swing Ride  21.931852\n",
      "23     Vertical Drop   8.854938\n",
      "24        Water Ride  15.296954\n",
      "25           Zipline  21.209739\n"
     ]
    }
   ],
   "source": [
    "if to_test:\n",
    "    # best_network1 = torch.load('network1_v2.pth')\n",
    "    # best_network2 = torch.load('network2_v2.pth')\n",
    "    # result = RMSE_for_Attraction(best_network1,best_network2)\n",
    "    print('RMSE for all Attractions', result.RMSE.mean())\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7f4e408-0ce1-4de0-b149-e4d358dd3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('version2result.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243da85-08bd-4fdc-b123-2a9cf7120e0e",
   "metadata": {},
   "source": [
    "*Result Combination*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd4e8e39-499a-4cde-941b-e2368d1a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.read_csv('version1result.csv')\n",
    "result2 = pd.read_csv('version2result.csv')\n",
    "result = pd.merge(result1,result2,on = 'attraction')\n",
    "result = result.drop(columns = ['Unnamed: 0_x','Unnamed: 0_y'])\n",
    "result = result.rename(columns = {'RMSE_x':'Markov1','RMSE_y':'Markov2'})\n",
    "result['Combined_RMSE'] = result[['Markov1', 'Markov2']].min(axis=1)\n",
    "result['Chosed_Model'] = np.where(result['Combined_RMSE'] == result['Markov1'], 'Markov1', 'Markov2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b715fbdf-a2f4-4a2d-832e-eb4dbf463d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model RMSE: 17.026918440768203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attraction</th>\n",
       "      <th>Markov1</th>\n",
       "      <th>Markov2</th>\n",
       "      <th>Combined_RMSE</th>\n",
       "      <th>Chosed_Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bumper Cars</td>\n",
       "      <td>12.496342</td>\n",
       "      <td>7.623577</td>\n",
       "      <td>7.623577</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bungee Jump</td>\n",
       "      <td>28.619547</td>\n",
       "      <td>20.003759</td>\n",
       "      <td>20.003759</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Circus Train</td>\n",
       "      <td>6.192073</td>\n",
       "      <td>3.888419</td>\n",
       "      <td>3.888419</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crazy Dance</td>\n",
       "      <td>0.044842</td>\n",
       "      <td>3.705589</td>\n",
       "      <td>0.044842</td>\n",
       "      <td>Markov1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dizzy Dropper</td>\n",
       "      <td>16.778949</td>\n",
       "      <td>10.570900</td>\n",
       "      <td>10.570900</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drop Tower</td>\n",
       "      <td>35.348845</td>\n",
       "      <td>21.876137</td>\n",
       "      <td>21.876137</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flying Coaster</td>\n",
       "      <td>20.745494</td>\n",
       "      <td>14.044068</td>\n",
       "      <td>14.044068</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Free Fall</td>\n",
       "      <td>49.920049</td>\n",
       "      <td>44.365342</td>\n",
       "      <td>44.365342</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Giant Wheel</td>\n",
       "      <td>49.385965</td>\n",
       "      <td>21.154676</td>\n",
       "      <td>21.154676</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Giga Coaster</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>9.930772</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>Markov1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Go-Karts</td>\n",
       "      <td>30.489797</td>\n",
       "      <td>21.436050</td>\n",
       "      <td>21.436050</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Haunted House</td>\n",
       "      <td>22.301925</td>\n",
       "      <td>14.451574</td>\n",
       "      <td>14.451574</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Himalaya Ride</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>2.787177</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>Markov1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inverted Coaster</td>\n",
       "      <td>23.829943</td>\n",
       "      <td>22.863536</td>\n",
       "      <td>22.863536</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kiddie Coaster</td>\n",
       "      <td>13.275166</td>\n",
       "      <td>11.530456</td>\n",
       "      <td>11.530456</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Merry Go Round</td>\n",
       "      <td>18.537053</td>\n",
       "      <td>13.787891</td>\n",
       "      <td>13.787891</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oz Theatre</td>\n",
       "      <td>6.540795</td>\n",
       "      <td>5.651201</td>\n",
       "      <td>5.651201</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rapids Ride</td>\n",
       "      <td>22.499213</td>\n",
       "      <td>17.194991</td>\n",
       "      <td>17.194991</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Roller Coaster</td>\n",
       "      <td>26.260995</td>\n",
       "      <td>23.407296</td>\n",
       "      <td>23.407296</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Spinning Coaster</td>\n",
       "      <td>24.238649</td>\n",
       "      <td>14.330277</td>\n",
       "      <td>14.330277</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Spiral Slide</td>\n",
       "      <td>88.738792</td>\n",
       "      <td>79.192839</td>\n",
       "      <td>79.192839</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Superman Ride</td>\n",
       "      <td>10.953985</td>\n",
       "      <td>7.905478</td>\n",
       "      <td>7.905478</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Swing Ride</td>\n",
       "      <td>50.071282</td>\n",
       "      <td>21.931852</td>\n",
       "      <td>21.931852</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Vertical Drop</td>\n",
       "      <td>8.849341</td>\n",
       "      <td>8.854938</td>\n",
       "      <td>8.849341</td>\n",
       "      <td>Markov1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Water Ride</td>\n",
       "      <td>27.440018</td>\n",
       "      <td>15.296954</td>\n",
       "      <td>15.296954</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Zipline</td>\n",
       "      <td>43.241618</td>\n",
       "      <td>21.209739</td>\n",
       "      <td>21.209739</td>\n",
       "      <td>Markov2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attraction    Markov1    Markov2  Combined_RMSE Chosed_Model\n",
       "0        Bumper Cars  12.496342   7.623577       7.623577      Markov2\n",
       "1        Bungee Jump  28.619547  20.003759      20.003759      Markov2\n",
       "2       Circus Train   6.192073   3.888419       3.888419      Markov2\n",
       "3        Crazy Dance   0.044842   3.705589       0.044842      Markov1\n",
       "4      Dizzy Dropper  16.778949  10.570900      10.570900      Markov2\n",
       "5         Drop Tower  35.348845  21.876137      21.876137      Markov2\n",
       "6     Flying Coaster  20.745494  14.044068      14.044068      Markov2\n",
       "7          Free Fall  49.920049  44.365342      44.365342      Markov2\n",
       "8        Giant Wheel  49.385965  21.154676      21.154676      Markov2\n",
       "9       Giga Coaster   0.070613   9.930772       0.070613      Markov1\n",
       "10          Go-Karts  30.489797  21.436050      21.436050      Markov2\n",
       "11     Haunted House  22.301925  14.451574      14.451574      Markov2\n",
       "12     Himalaya Ride   0.018071   2.787177       0.018071      Markov1\n",
       "13  Inverted Coaster  23.829943  22.863536      22.863536      Markov2\n",
       "14    Kiddie Coaster  13.275166  11.530456      11.530456      Markov2\n",
       "15    Merry Go Round  18.537053  13.787891      13.787891      Markov2\n",
       "16        Oz Theatre   6.540795   5.651201       5.651201      Markov2\n",
       "17       Rapids Ride  22.499213  17.194991      17.194991      Markov2\n",
       "18    Roller Coaster  26.260995  23.407296      23.407296      Markov2\n",
       "19  Spinning Coaster  24.238649  14.330277      14.330277      Markov2\n",
       "20      Spiral Slide  88.738792  79.192839      79.192839      Markov2\n",
       "21     Superman Ride  10.953985   7.905478       7.905478      Markov2\n",
       "22        Swing Ride  50.071282  21.931852      21.931852      Markov2\n",
       "23     Vertical Drop   8.849341   8.854938       8.849341      Markov1\n",
       "24        Water Ride  27.440018  15.296954      15.296954      Markov2\n",
       "25           Zipline  43.241618  21.209739      21.209739      Markov2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Combined Model RMSE:',result.Combined_RMSE.mean())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d62d40b-beed-4940-9759-b8bee04ca276",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv('version2result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e2e9b43-5ea0-4a68-88e9-a97f1772c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.297570765424718"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[~result['attraction'].isin(['Spiral Slide', 'Free Fall'])].Combined_RMSE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbda10-7a5c-484e-8f35-70fba2543a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
